{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\r\n",
        "import os\r\n",
        "import csv\r\n",
        "\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from sklearn import datasets\r\n",
        "import pkg_resources\r\n",
        "\r\n",
        "import azureml.core\r\n",
        "from azureml.core.experiment import Experiment\r\n",
        "from azureml.core.workspace import Workspace\r\n",
        "from azureml.train.automl import AutoMLConfig\r\n",
        "from azureml.core.dataset import Dataset\r\n",
        "\r\n",
        "from azureml.pipeline.steps import AutoMLStep\r\n",
        "\r\n",
        "# Check core SDK version number\r\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.30.0\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1624432920111
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "### Overview\n",
        "TODO: In this markdown cell, give an overview of the dataset you are using. Also mention the task you will be performing.\n",
        "\n",
        "\n",
        "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "# choose a name for experiment\n",
        "experiment_name = 'CapstoneProject'\n",
        "project_folder = './capstone-project'\n",
        "\n",
        "experiment=Experiment(ws, experiment_name)\n",
        "experiment"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "Experiment(Name: CapstoneProject,\nWorkspace: quick-starts-ws-147759)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>CapstoneProject</td><td>quick-starts-ws-147759</td><td><a href=\"https://ml.azure.com/experiments/id/e56f77dd-2b29-47fb-abd9-b05a4150c043?wsid=/subscriptions/f9d5a085-54dc-4215-9ba6-dad5d86e60a0/resourcegroups/aml-quickstarts-147759/workspaces/quick-starts-ws-147759&amp;tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1624432920798
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the compute cluster\r\n",
        "\r\n",
        "from azureml.core.compute import AmlCompute\r\n",
        "from azureml.core.compute import ComputeTarget\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "# NOTE: update the cluster name to match the existing cluster\r\n",
        "# Choose a name for your CPU cluster\r\n",
        "amlcompute_cluster_name = \"CapstoneAML\"\r\n",
        "\r\n",
        "# Verify that cluster does not exist already\r\n",
        "try:\r\n",
        "    compute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\r\n",
        "    print('Found existing cluster, use it.')\r\n",
        "except ComputeTargetException:\r\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS3_V2',\r\n",
        "                                                           min_nodes=1, # for GPU, use \"STANDARD_NC6\"\r\n",
        "                                                           #vm_priority = 'lowpriority', # optional\r\n",
        "                                                           max_nodes=6)\r\n",
        "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\r\n",
        "\r\n",
        "compute_target.wait_for_completion(show_output=True, min_node_count = 1, timeout_in_minutes = 10)\r\n",
        "# For a more detailed view of current AmlCompute status, use get_status()."
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing cluster, use it.\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624432921374
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "found = False\r\n",
        "key = \"HeartFailureRate\"\r\n",
        "description_text = \"Dataset for heart failure recommendation\"\r\n",
        "\r\n",
        "if key in ws.datasets.keys(): \r\n",
        "        found = True\r\n",
        "        dataset = ws.datasets[key] \r\n",
        "\r\n",
        "df = dataset.to_pandas_dataframe()\r\n",
        "df.describe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "              age     anaemia  creatinine_phosphokinase    diabetes  \\\ncount  299.000000  299.000000                299.000000  299.000000   \nmean    60.833893    0.431438                581.839465    0.418060   \nstd     11.894809    0.496107                970.287881    0.494067   \nmin     40.000000    0.000000                 23.000000    0.000000   \n25%     51.000000    0.000000                116.500000    0.000000   \n50%     60.000000    0.000000                250.000000    0.000000   \n75%     70.000000    1.000000                582.000000    1.000000   \nmax     95.000000    1.000000               7861.000000    1.000000   \n\n       ejection_fraction  high_blood_pressure      platelets  \\\ncount         299.000000           299.000000     299.000000   \nmean           38.083612             0.351171  263358.029264   \nstd            11.834841             0.478136   97804.236869   \nmin            14.000000             0.000000   25100.000000   \n25%            30.000000             0.000000  212500.000000   \n50%            38.000000             0.000000  262000.000000   \n75%            45.000000             1.000000  303500.000000   \nmax            80.000000             1.000000  850000.000000   \n\n       serum_creatinine  serum_sodium         sex    smoking        time  \\\ncount         299.00000    299.000000  299.000000  299.00000  299.000000   \nmean            1.39388    136.625418    0.648829    0.32107  130.260870   \nstd             1.03451      4.412477    0.478136    0.46767   77.614208   \nmin             0.50000    113.000000    0.000000    0.00000    4.000000   \n25%             0.90000    134.000000    0.000000    0.00000   73.000000   \n50%             1.10000    137.000000    1.000000    0.00000  115.000000   \n75%             1.40000    140.000000    1.000000    1.00000  203.000000   \nmax             9.40000    148.000000    1.000000    1.00000  285.000000   \n\n       DEATH_EVENT  \ncount    299.00000  \nmean       0.32107  \nstd        0.46767  \nmin        0.00000  \n25%        0.00000  \n50%        0.00000  \n75%        1.00000  \nmax        1.00000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>anaemia</th>\n      <th>creatinine_phosphokinase</th>\n      <th>diabetes</th>\n      <th>ejection_fraction</th>\n      <th>high_blood_pressure</th>\n      <th>platelets</th>\n      <th>serum_creatinine</th>\n      <th>serum_sodium</th>\n      <th>sex</th>\n      <th>smoking</th>\n      <th>time</th>\n      <th>DEATH_EVENT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>299.000000</td>\n      <td>299.000000</td>\n      <td>299.000000</td>\n      <td>299.000000</td>\n      <td>299.000000</td>\n      <td>299.000000</td>\n      <td>299.000000</td>\n      <td>299.00000</td>\n      <td>299.000000</td>\n      <td>299.000000</td>\n      <td>299.00000</td>\n      <td>299.000000</td>\n      <td>299.00000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>60.833893</td>\n      <td>0.431438</td>\n      <td>581.839465</td>\n      <td>0.418060</td>\n      <td>38.083612</td>\n      <td>0.351171</td>\n      <td>263358.029264</td>\n      <td>1.39388</td>\n      <td>136.625418</td>\n      <td>0.648829</td>\n      <td>0.32107</td>\n      <td>130.260870</td>\n      <td>0.32107</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>11.894809</td>\n      <td>0.496107</td>\n      <td>970.287881</td>\n      <td>0.494067</td>\n      <td>11.834841</td>\n      <td>0.478136</td>\n      <td>97804.236869</td>\n      <td>1.03451</td>\n      <td>4.412477</td>\n      <td>0.478136</td>\n      <td>0.46767</td>\n      <td>77.614208</td>\n      <td>0.46767</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>40.000000</td>\n      <td>0.000000</td>\n      <td>23.000000</td>\n      <td>0.000000</td>\n      <td>14.000000</td>\n      <td>0.000000</td>\n      <td>25100.000000</td>\n      <td>0.50000</td>\n      <td>113.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>4.000000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>51.000000</td>\n      <td>0.000000</td>\n      <td>116.500000</td>\n      <td>0.000000</td>\n      <td>30.000000</td>\n      <td>0.000000</td>\n      <td>212500.000000</td>\n      <td>0.90000</td>\n      <td>134.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>73.000000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>60.000000</td>\n      <td>0.000000</td>\n      <td>250.000000</td>\n      <td>0.000000</td>\n      <td>38.000000</td>\n      <td>0.000000</td>\n      <td>262000.000000</td>\n      <td>1.10000</td>\n      <td>137.000000</td>\n      <td>1.000000</td>\n      <td>0.00000</td>\n      <td>115.000000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>70.000000</td>\n      <td>1.000000</td>\n      <td>582.000000</td>\n      <td>1.000000</td>\n      <td>45.000000</td>\n      <td>1.000000</td>\n      <td>303500.000000</td>\n      <td>1.40000</td>\n      <td>140.000000</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n      <td>203.000000</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>95.000000</td>\n      <td>1.000000</td>\n      <td>7861.000000</td>\n      <td>1.000000</td>\n      <td>80.000000</td>\n      <td>1.000000</td>\n      <td>850000.000000</td>\n      <td>9.40000</td>\n      <td>148.000000</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n      <td>285.000000</td>\n      <td>1.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624432929116
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "TODO: Explain why you chose the automl settings and cofiguration you used below.\n",
        "\n",
        "I have chosen experimentation time out as the dataset is smaller and it can be covered within 20 minutes. \n",
        "The max concurrent iteration is 5 ( 1 less than total number of compute nodes in the cluster). \n",
        "The primary_metric is chosen as AUC_weighted orginally to handle balanced data better. \n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Put your automl settings here\n",
        "automl_settings = {\n",
        "    \"experiment_timeout_minutes\": 20,\n",
        "    \"max_concurrent_iterations\": 5,\n",
        "    \"primary_metric\" : 'accuracy'\n",
        "}\n",
        "\n",
        "# TODO: Put your automl config here\n",
        "automl_config = AutoMLConfig(compute_target=compute_target,\n",
        "                             task = \"classification\",\n",
        "                             training_data=dataset,\n",
        "                             label_column_name=\"DEATH_EVENT\",   \n",
        "                             path = project_folder,\n",
        "                             enable_early_stopping= True,\n",
        "                             featurization= 'auto',\n",
        "                             debug_log = \"automl_errors.log\",\n",
        "                             **automl_settings\n",
        "                            )"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1624432929325
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Submit your experiment\n",
        "remote_run = experiment.submit(automl_config)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConfigException",
          "evalue": "ConfigException:\n\tMessage: Invalid argument(s) 'primary_metric' specified. Supported value(s): 'norm_macro_recall, AUC_weighted, average_precision_score_weighted, accuracy, precision_score_weighted'.\n\tInnerException: None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Invalid argument(s) 'primary_metric' specified. Supported value(s): 'norm_macro_recall, AUC_weighted, average_precision_score_weighted, accuracy, precision_score_weighted'.\",\n        \"details_uri\": \"https://aka.ms/AutoMLConfig\",\n        \"target\": \"primary_metric\",\n        \"inner_error\": {\n            \"code\": \"BadArgument\",\n            \"inner_error\": {\n                \"code\": \"ArgumentInvalid\"\n            }\n        }\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConfigException\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-2dd33d13fc7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO: Submit your experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mremote_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoml_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/experiment.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, config, tags, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0msubmit_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_experiment_submit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"submit config {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtags\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/train/automl/automlconfig.py\u001b[0m in \u001b[0;36m_automl_static_submit\u001b[0;34m(automl_config_object, workspace, experiment_name, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# retrieve settings which are present in user but not part of fit_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0msettings_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mautoml_config_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0msettings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_azureautomlsettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAzureAutoMLSettings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msettings_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mlog_server\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_log_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_run_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent_run_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/train/automl/_azureautomlsettings.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, experiment, path, iterations, data_script, primary_metric, task_type, compute_target, spark_context, test_size, validation_size, n_cross_validations, y_min, y_max, num_classes, featurization, max_cores_per_iteration, max_concurrent_iterations, iteration_timeout_minutes, mem_in_mb, enforce_time_on_windows, experiment_timeout_minutes, experiment_exit_score, enable_early_stopping, blacklist_models, whitelist_models, exclude_nan_labels, verbosity, debug_log, debug_flag, enable_voting_ensemble, enable_stack_ensemble, ensemble_iterations, model_explainability, enable_tf, enable_subsampling, subsample_seed, cost_mode, is_timeseries, enable_onnx_compatible_models, scenario, environment_label, show_deprecate_warnings, enable_local_managed, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0menable_local_managed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menable_local_managed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0menvironment_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menvironment_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# temporary measure to bypass the typecheck in base settings in common core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/automl/core/automl_base_settings.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, iterations, data_script, primary_metric, task_type, test_size, validation_size, n_cross_validations, y_min, y_max, num_classes, featurization, max_cores_per_iteration, max_concurrent_iterations, iteration_timeout_minutes, mem_in_mb, enforce_time_on_windows, experiment_timeout_minutes, experiment_exit_score, blocked_models, blacklist_models, allowed_models, whitelist_models, exclude_nan_labels, verbosity, debug_log, debug_flag, enable_voting_ensemble, enable_stack_ensemble, ensemble_iterations, model_explainability, enable_tf, enable_subsampling, subsample_seed, cost_mode, is_timeseries, enable_early_stopping, early_stopping_n_iters, enable_onnx_compatible_models, enable_feature_sweeping, enable_nimbusml, enable_streaming, force_streaming, label_column_name, weight_column_name, cv_split_column_names, enable_local_managed, vm_type, track_child_runs, show_deprecate_warnings, forecasting_parameters, allowed_private_models, scenario, environment_label, save_mlflow, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m                     AzureMLError.create(\n\u001b[1;32m    260\u001b[0m                         \u001b[0mInvalidArgumentWithSupportedValues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"primary_metric\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m                         \u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"primary_metric\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupported_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_primary_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m                     )\n\u001b[1;32m    263\u001b[0m                 )\n",
            "\u001b[0;31mConfigException\u001b[0m: ConfigException:\n\tMessage: Invalid argument(s) 'primary_metric' specified. Supported value(s): 'norm_macro_recall, AUC_weighted, average_precision_score_weighted, accuracy, precision_score_weighted'.\n\tInnerException: None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Invalid argument(s) 'primary_metric' specified. Supported value(s): 'norm_macro_recall, AUC_weighted, average_precision_score_weighted, accuracy, precision_score_weighted'.\",\n        \"details_uri\": \"https://aka.ms/AutoMLConfig\",\n        \"target\": \"primary_metric\",\n        \"inner_error\": {\n            \"code\": \"BadArgument\",\n            \"inner_error\": {\n                \"code\": \"ArgumentInvalid\"\n            }\n        }\n    }\n}"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1624429676693
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\r\n",
        "RunDetails(remote_run).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1624429677531
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# waiting for the run \r\n",
        "\r\n",
        "remote_run.wait_for_completion()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624430900874
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Best model\r\n",
        "\r\n",
        "# Retrieve best model from remote Run\r\n",
        "best_model_output = remote_run.get_pipeline_output(best_model_output_name)\r\n",
        "num_file_downloaded = best_model_output.download('.', show_progress=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431425670
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#properties\r\n",
        "\r\n",
        "import pickle\r\n",
        "\r\n",
        "with open(best_model_output._path_on_datastore, \"rb\" ) as f:\r\n",
        "    best_model = pickle.load(f)\r\n",
        "best_model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.steps"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Save the best model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431426111
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431435189
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598432707604
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}